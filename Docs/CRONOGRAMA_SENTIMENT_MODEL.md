# üß† Cronograma: Implementaci√≥n de Modelo de Sentimiento

## üìä Objetivo
Entrenar e integrar modelo de an√°lisis de sentimiento con **XLM-RoBERTa base** para reemplazar la simulaci√≥n emocional actual por inferencia real.

---

## üóìÔ∏è D√≠a 1: Preparaci√≥n del Dataset (5 horas)

### üì• Recolecci√≥n de datos (1h)
**Fuente:** Entrevistas simuladas del `chat_simulator.py`

**Tareas:**
- [ ] Extraer respuestas de candidatos del chat_simulator
- [ ] Recolectar respuestas reales de `Logs/reports/rrhh_registry.csv`
- [ ] Agregar respuestas de `emotional_log_*.csv`

**Output esperado:**
```python
{
    "text": "I'd use async/await and proper error handling.",
    "candidate": "Luis",
    "vacancy": "Backend Node + RoR Developer",
    "context": "technical_interview"
}
```

### üè∑Ô∏è Etiquetado emocional (2h)
**Clases emocionales:**
- `enthusiastic` - Alta energ√≠a, positivo
- `confident` - Seguro, profesional
- `neutral` - Equilibrado, informativo
- `anxious` - Nervioso, inseguro
- `frustrated` - Irritado, negativo
- `negative` - Pesimista, desanimado

**Criterios de etiquetado:**
```python
# Indicadores por clase
INDICATORS = {
    "enthusiastic": ["!", "great", "love", "excited", "definitely"],
    "confident": ["yes", "of course", "certainly", "I know", "I have"],
    "neutral": ["okay", "I think", "maybe", "could be"],
    "anxious": ["not sure", "I guess", "perhaps", "maybe"],
    "frustrated": ["but", "however", "don't", "can't"],
    "negative": ["no", "never", "impossible", "difficult"]
}
```

**Tareas:**
- [ ] Crear script de etiquetado semi-autom√°tico
- [ ] Revisar y validar etiquetas manualmente
- [ ] Documentar criterios de clasificaci√≥n

### üßπ Limpieza y formato (1h)
**Tareas:**
- [ ] Normalizar texto (lowercase, eliminar caracteres especiales)
- [ ] Tokenizaci√≥n b√°sica
- [ ] Convertir a formato JSON/CSV para entrenamiento
- [ ] Dividir en train/validation/test (70/15/15)

**Formato objetivo:**
```json
[
  {
    "text": "i'd use async/await and proper error handling",
    "label": "confident",
    "metadata": {
      "candidate": "Luis",
      "vacancy": "Backend Developer",
      "language": "en"
    }
  }
]
```

### üìä Balance de clases (1h)
**Tareas:**
- [ ] Analizar distribuci√≥n de clases
- [ ] Aplicar t√©cnicas de balanceo si es necesario:
  - Oversampling de clases minoritarias
  - Undersampling de clases mayoritarias
  - Data augmentation (parafraseo)

**Target de distribuci√≥n:**
```
enthusiastic: 15-20%
confident: 15-20%
neutral: 20-25%
anxious: 15-20%
frustrated: 10-15%
negative: 10-15%
```

---

## üóìÔ∏è D√≠a 2: Configuraci√≥n y Entrenamiento (5.5 horas)

### üß† Carga de modelo (1h)
**Modelo base:** `xlm-roberta-base` (279M par√°metros)

**Tareas:**
- [ ] Instalar dependencias:
  ```bash
  pip install transformers torch datasets evaluate scikit-learn
  ```
- [ ] Cargar tokenizer y modelo pre-entrenado
- [ ] Configurar clasificaci√≥n para 6 clases emocionales
- [ ] Verificar compatibilidad con GPU (si disponible)

**Script inicial:**
```python
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification

model_name = "xlm-roberta-base"
tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)
model = XLMRobertaForSequenceClassification.from_pretrained(
    model_name, 
    num_labels=6  # 6 clases emocionales
)
```

### üß™ Fine-tuning (3h)
**Hiperpar√°metros sugeridos:**
```python
training_args = {
    "learning_rate": 2e-5,
    "batch_size": 16,
    "epochs": 3-5,
    "weight_decay": 0.01,
    "warmup_steps": 500,
    "evaluation_strategy": "epoch"
}
```

**Tareas:**
- [ ] Preparar DataLoader con dataset balanceado
- [ ] Configurar Trainer de Hugging Face
- [ ] Entrenar con validaci√≥n por epoch
- [ ] Monitorear loss y accuracy
- [ ] Guardar checkpoints

**M√©tricas a monitorear:**
- Training loss
- Validation loss
- Accuracy
- F1-score (macro)

### üìà Evaluaci√≥n (1h)
**Tareas:**
- [ ] Calcular m√©tricas en test set:
  - Accuracy general
  - Precision, Recall, F1 por clase
  - Matriz de confusi√≥n
- [ ] Analizar errores comunes
- [ ] Identificar clases problem√°ticas

**M√©tricas objetivo:**
- Accuracy general: >75%
- F1-score por clase: >0.65
- Confusi√≥n entre clases adyacentes es aceptable (enthusiastic ‚Üî confident)

### üíæ Exportaci√≥n (0.5h)
**Tareas:**
- [ ] Guardar modelo entrenado:
  ```python
  model.save_pretrained("Models/xlm-roberta-sentiment")
  tokenizer.save_pretrained("Models/xlm-roberta-sentiment")
  ```
- [ ] Exportar configuraci√≥n y m√©tricas
- [ ] Crear archivo README del modelo
- [ ] Version control del modelo (Git LFS o similar)

---

## üóìÔ∏è D√≠a 3: Integraci√≥n al TRS Engine Core (4 horas)

### üîó M√≥dulo `sentiment_model.py` (1.5h)
**Crear nuevo m√≥dulo:** `Modules/sentiment_model.py`

**Funcionalidades:**
```python
class SentimentAnalyzer:
    def __init__(self, model_path):
        """Cargar modelo entrenado"""
        
    def predict_emotion(self, text, language="auto"):
        """
        Predecir emoci√≥n de un texto
        
        Returns:
            {
                "emotion": "confident",
                "confidence": 0.87,
                "all_scores": {...}
            }
        """
        
    def predict_batch(self, texts):
        """Predicci√≥n en lote para m√∫ltiples textos"""
        
    def detect_language(self, text):
        """Detectar idioma del texto (es/en)"""
```

**Tareas:**
- [ ] Implementar clase SentimentAnalyzer
- [ ] Funci√≥n de inferencia optimizada
- [ ] Detecci√≥n autom√°tica de idioma
- [ ] Manejo de errores y edge cases
- [ ] Tests unitarios b√°sicos

### üîÑ Conexi√≥n con `emotional_inference_engine.py` (1h)
**Modificaciones necesarias:**

**ANTES (simulado):**
```python
def generate_message(profile, match_score, penalty):
    tone = profile["emotional_state"]  # Viene de profiles.json
    ...
```

**DESPU√âS (real):**
```python
from sentiment_model import SentimentAnalyzer

analyzer = SentimentAnalyzer("Models/xlm-roberta-sentiment")

def infer_emotional_state(candidate_responses):
    """Inferir emoci√≥n basada en respuestas reales"""
    emotions = []
    for response in candidate_responses:
        result = analyzer.predict_emotion(response["text"])
        emotions.append(result["emotion"])
    
    # Emoci√≥n predominante o promedio ponderado
    return aggregate_emotions(emotions)
```

**Tareas:**
- [ ] Integrar SentimentAnalyzer en el engine
- [ ] Reemplazar emotional_state simulado por inferencia real
- [ ] Mantener compatibilidad con flujo existente
- [ ] Agregar logging de inferencias

### ‚úçÔ∏è Adaptaci√≥n de `emotional_closure.py` (1h)
**Mejoras al m√≥dulo de cierre:**

```python
def generate_closing_message(candidate_name, emotional_state, vacancy_name, confidence=None):
    """
    Generar mensaje adaptativo con informaci√≥n de confianza
    
    Args:
        emotional_state: Emoci√≥n inferida por el modelo
        confidence: Score de confianza (0-1)
    """
    
    # Ajustar mensaje seg√∫n nivel de confianza
    if confidence and confidence < 0.6:
        # Usar mensaje m√°s neutro si hay baja confianza
        return get_neutral_message(candidate_name, vacancy_name)
    
    # Mensaje espec√≠fico seg√∫n emoci√≥n con alta confianza
    return get_emotion_specific_message(...)
```

**Tareas:**
- [ ] Agregar par√°metro de confidence al mensaje
- [ ] Crear mensajes de respaldo para baja confianza
- [ ] Enriquecer mensajes con contexto emocional
- [ ] Actualizar tests

### üì§ Exportaci√≥n a ficha t√©cnica (0.5h)
**Agregar campos al reporte:**

```python
# En report_generator.py
def generate_candidate_section(...):
    ...
    md += f"\n#### üß† Emotional Analysis (AI-powered)\n"
    md += f"- **Detected Emotion:** {emotion}\n"
    md += f"- **Confidence Score:** {confidence:.2f}\n"
    md += f"- **Model:** XLM-RoBERTa base\n"
    md += f"- **Analysis Timestamp:** {timestamp}\n"
```

**Tareas:**
- [ ] Agregar secci√≥n de an√°lisis emocional AI
- [ ] Incluir confidence score en reportes
- [ ] Documentar modelo usado
- [ ] Agregar columnas al CSV

---

## üóìÔ∏è D√≠a 4: Validaci√≥n y Ajustes (3 horas - OPCIONAL)

### üß™ Pruebas con entrevistas reales (1h)
**Tareas:**
- [ ] Ejecutar pipeline completo con modelo real
- [ ] Validar inferencias en 20-30 entrevistas
- [ ] Comparar emociones inferidas vs esperadas
- [ ] Documentar casos problem√°ticos

### üîÑ Ajuste de clases o umbrales (1h)
**Posibles ajustes:**
- [ ] Re-entrenamiento con casos problem√°ticos
- [ ] Ajuste de thresholds de confianza
- [ ] Refinamiento de clases muy similares
- [ ] Mejora de mensajes de cierre

### üìä Comparaci√≥n con simulador (1h)
**M√©tricas de impacto:**
- Tasa de consentimiento: simulado vs real
- Distribuci√≥n de emociones: simulado vs real
- Coherencia de mensajes de cierre
- Experiencia del usuario

**Tareas:**
- [ ] An√°lisis A/B (simulado vs real)
- [ ] Reportar mejoras/diferencias
- [ ] Documentar recomendaciones
- [ ] Preparar presentaci√≥n de resultados

---

## ‚è±Ô∏è Resumen de Tiempo

| D√≠a | Tareas | Tiempo |
|-----|--------|--------|
| D√≠a 1 | Preparaci√≥n del dataset | 5h |
| D√≠a 2 | Entrenamiento | 5.5h |
| D√≠a 3 | Integraci√≥n | 4h |
| D√≠a 4 | Validaci√≥n (opcional) | 3h |
| **TOTAL** | | **16-20h** |

---

## üìÅ Estructura de Archivos Nueva

```
TRS_Engine_Core/
‚îú‚îÄ‚îÄ Models/                              # NUEVO
‚îÇ   ‚îî‚îÄ‚îÄ xlm-roberta-sentiment/
‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ       ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ       ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ       ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Modules/
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_model.py              # NUEVO
‚îÇ   ‚îú‚îÄ‚îÄ emotional_inference_engine.py   # MODIFICADO
‚îÇ   ‚îú‚îÄ‚îÄ emotional_closure.py            # MODIFICADO
‚îÇ   ‚îî‚îÄ‚îÄ report_generator.py             # MODIFICADO
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îî‚îÄ‚îÄ sentiment_training/             # NUEVO
‚îÇ       ‚îú‚îÄ‚îÄ train.json
‚îÇ       ‚îú‚îÄ‚îÄ validation.json
‚îÇ       ‚îî‚îÄ‚îÄ test.json
‚îî‚îÄ‚îÄ Notebooks/
    ‚îî‚îÄ‚îÄ sentiment_model_training.ipynb  # NUEVO
```

---

## üéØ Criterios de √âxito

### T√©cnicos
- [ ] Modelo con accuracy >75% en test set
- [ ] F1-score >0.65 por clase
- [ ] Inferencia <500ms por texto
- [ ] Integraci√≥n sin breaking changes

### Funcionales
- [ ] Pipeline ejecuta end-to-end con modelo real
- [ ] Reportes incluyen an√°lisis emocional AI
- [ ] Mensajes de cierre coherentes con emoci√≥n detectada
- [ ] Documentaci√≥n completa

### De Negocio
- [ ] Mejora en tasa de consentimiento (vs simulado)
- [ ] Mayor precisi√≥n en clasificaci√≥n emocional
- [ ] Sistema listo para producci√≥n
- [ ] Presentaci√≥n para hackathon completa

---

## üöÄ Pr√≥ximos Pasos Inmediatos

1. **Crear estructura de carpetas**
2. **Extraer datos de entrevistas existentes**
3. **Comenzar etiquetado del dataset**
4. **Instalar dependencias necesarias**

---

**Fecha creaci√≥n:** 2025-11-07  
**Versi√≥n:** 1.0  
**Hackathon ready:** 3-4 d√≠as

